# Balanced sampling {#Balanced}

Similar to the regression estimator, balanced sampling is a sampling method that exploits one or more quantitative covariates that are related to the variable of interest. The idea behind balanced sampling is that, if we know the mean of the covariates, then the sampling efficiency can be increased by selecting a sample whose averages of the covariates is equal to the population means of the covariates.

The simulated population Figure\@ref(fig:simpleexample) shows a linear trend from West to East. In other words, the simulated study variable is correlated with the covariate Easting. To estimate the population mean of the simulated study variable, intuitively it is attractive to select a sample with an average of the Easting coordinate that is equal to the population mean of Easting (which is 10). Figure\@ref(fig:simpleexample)(a) shows such a sample; we say that the sample is `balanced' on the covariate Easting.

```{r simpleexample, out.width='50%',fig.asp=1, fig.show='hold', fig.cap = "Sample balanced on Easting (a) and on Easting and Northing (b)", echo=FALSE, cache=T}
#define residual variogram for simulation
vgmodel = vgm(model = "Exp", psill = 10, range = 4, nugget = 0)

#define discretisation grid
x<-seq(1:20)-0.5
y<-x
grid<-expand.grid(x,y)
names(grid)<-c("x1","x2")
distx<-outer(grid$x1,grid$x1,FUN="-")
disty<-outer(grid$x2,grid$x2,FUN="-")
dist<-sqrt(distx^2+disty^2)

#compute matrix with covariances
C = variogramLine(vgmodel, dist_vector = dist, covariance = TRUE)

#now simulate values for grid by Cholesky decomposition
Upper<-chol(C)

set.seed(31415)
G<-rnorm(n=nrow(grid),0,1) #simulate random numbers from standard normal distribution

#trend coefficient in x-direction
b1 <- 2
b2 <- 1
grid$z<-crossprod(Upper,G)+b1*grid$x1 +b2*grid$x2

#compute population size
N<-nrow(grid)

#set sample size)
n<-4

#define matrix with covariate for balancing; first column of matrix must be filled with ones
X<-cbind(rep(1,times=N),grid$x1)

#compute inclusion probabilities; use equal probabilities
pik<-rep(n/N,times=N)

nsam<-100
Meanx<-mean(grid$x1)
set.seed(31415)
for (i in 1:nsam) {
    sampleind=samplecube(X=X,pik=pik,comment=FALSE,method=1)
    sam<-grid[sampleind==1,]
    samplemeanx<-mean(sam$x1)
    if (samplemeanx == Meanx) {break}    
}
ggplot(data = grid) +
  geom_tile(mapping = aes(x = x1, y = x2, fill = z)) +
  geom_tile(data=sam,mapping = aes(x = x1, y = x2),colour="red",size=0.5,width=1,height=1,fill=NA)+
  ggtitle("a")+
  theme(plot.title = element_text(size=14, hjust=0.5))+
  scale_fill_gradient(name="z",low = "skyblue", high = "darkblue") +
  scale_y_continuous(name = "Northing") +
  scale_x_continuous(name = "Easting") +
  coord_equal()

#now select a sample balanced on Easting and Northing
X<-cbind(rep(1,times=N),grid$x1,grid$x2)

meanx1<-mean(grid$x1)
meanx2<-mean(grid$x2)
nsam<-1000
set.seed(314)
for (i in 1:nsam) {
  sampleind=samplecube(X=X,pik=pik,comment=FALSE,method=1)
  sam1<-grid[sampleind==1,]
  samplemeanx1<-mean(sam1$x1)
  samplemeanx2<-mean(sam1$x2)
  if (samplemeanx1 == meanx1 & samplemeanx2 == meanx2) {break}    
}
ggplot(data = grid) +
  geom_tile(mapping = aes(x = x1, y = x2, fill = z)) +
  geom_tile(data=sam1,mapping = aes(x = x1, y = x2),colour="red",size=0.5,width=1,height=1,fill=NA)+
  ggtitle("b")+
  theme(plot.title = element_text(size=14, hjust=0.5))+
  scale_fill_gradient(name="z",low = "skyblue", high = "darkblue") +
  scale_y_continuous(name = "Northing") +
  scale_x_continuous(name = "Easting") +
  coord_equal()
```

## Balanced sample versus balanced sampling design
We must distinguish a balanced *sample* from a balanced sampling *design*. A sampling design is balanced on a covariate $x$ when *all possible* samples that can be generated by the design are balanced on $x$. So, simple random sampling is not a balanced sampling design, because for many simple random samples the sample average of $x$ is not equal to the population mean of $x$. Only the *expectation* of the sample average of $x$, i.e. the mean of the sample average over an infinite number of simple random samples, equals the population mean of $x$.

Figure \@ref(fig:scatterplotsqerror) shows for one thousand simple random samples the squared error of the estimated population mean of the study variable $z$ against the difference between the sample mean of $x$ and the population mean of $x$.

```{r scatterplotsqerror, out.width='70%', fig.asp=1, echo=F,fig.cap="Squared error in estimated mean of $z$ against difference between population and sample mean of a covariate"}
nsam<-1000
n<-4
samplemeanz<-samplemeanx<-numeric(length=nsam)
set.seed(31415)
for (i in 1:nsam) {
  #select simple random sample from the data
  sampleind<-sample.int(nrow(grid),size=n)
  samplemeanz[i]<-mean(grid$z[sampleind])
  samplemeanx[i]<-mean(grid$x1[sampleind])
}

sqerror<-(samplemeanz-mean(grid$z))^2
devx<-samplemeanx-mean(grid$x1)
df<-data.frame(sqerror,devx)
ggplot(data = df) +
  geom_point(aes(y=sqerror,x=devx),size=2) +
  scale_x_continuous(name = "Sample average x - population mean x",limits=c(-9,9)) +
  scale_y_continuous(name = "Squared error")
```

Clearly, the larger the absolute value of the difference, the larger on average the squared error. So to obtain a precise estimate of the population mean of $z$, we better select samples with a difference close to 0.

Sampling designs can also be balanced on multiple covariates. Figure\@ref(fig:simpleexample)(b) shows a sample balanced on both Easting and Northing. Using Easting as a balancing variable reduced the sampling variance of the estimated mean substantially, see Table \@ref(tab:tablebalanced). Using Northing as a second balancing variable further reduced the sampling variance.  

```{r tablebalanced, tidy=FALSE, echo=F}
tbl <- data.frame(x=c("SI","Balanced","Balanced"),y=c("-","Easting","Easting+Northing"),z=c(39.7,14.4,9.77))

knitr::kable(
  head(tbl, 20), caption = 'Sampling variances of estimated mean for SI and balanced sampling of four units',
  col.names=c("Sampling design","Balancing variables","Sampling variance"),
  booktabs = TRUE
)
```

## Unequal inclusion probabilities
Until now I assumed that the inclusion probabilities of the population units are equal, but this is not a requirement for balanced sampling designs. A more general definition is: a sampling design is balanced on variable $x$ when for all samples generated by the design the Horvitz-Thompson estimator of the population mean of $x$ equals the population mean:  
\begin{equation}
\frac{1}{N} \sum_{k=1}^{n} \frac{x_k}{\pi_k}= \frac{1}{N} \sum_{k=1}^{N} x_k
(\#eq:generaldefinitionbalanced)
\end{equation}
In this equation $n$ is the sample size, $\pi_k$ is the inclusion probability of unit $k$, and $N$ is the total number of units in the population.

Similar to the regression estimator, balanced sampling exploits the linear relation between the variable of interest and one or more covariates. In the regression estimator this is done at the estimation stage. Balanced sampling does so at the sampling stage. For a single covariate the regression estimator equals (see Equation \@ref(eq:RegressionEstimatorSI))
\begin{equation}
\hat{\bar{z}}_{\mathrm{regr}} = \hat{\bar{z}}_{\mathrm{HT}} + b(\bar{x} - \hat{\bar{x}}_{\mathrm{HT}}) \;,
(\#eq:RegressionEstimatoranydesign)
\end{equation}
with $\hat{\bar{z}}_{\mathrm{HT}}$ and $\hat{\bar{x}}_{\mathrm{HT}}$ the Horvitz-Thompson estimators of the mean of the study variable $z$ and the covariate $x$, respectively, $\bar{x}$ the population mean of the covariate, and $b$ the estimated slope of the regression line. With a perfectly balanced sample the adjustment term in the regression estimator (the second term) equals zero.

Balanced samples can be selected with the cube algorithm @Deville2004, see also @Brus2015 for a detailed description of this algorithm. The population mean can be estimated by the Horvitz-Thompson estimator:
\begin{equation}
\hat{\bar{z}}_{\mathrm{bal}} = \frac{1}{N}\sum_{i=1}^n \frac{z_i}{\pi_i}.
(\#eq:HTMeanBalanced)
\end{equation}
So with equal inclusion probabilities, equal to $n/N$, the mean is estimated by the sample mean of the study variable. The variance of the estimated mean can be approximated by [@Grafstrom2013]
\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{bal}}\right)=\frac{1}{N}\frac{n}{n-p}\sum_{i=1}^n (1-\pi_i)\left(\frac{e_i}{\pi_i}\right)^2\;,
(\#eq:VarMeanBalanced)
\end{equation}
with $p$ the number of balancing variables, and $e_i = z_i - \mathbf{x}_i^{\text{T}}\hat{\boldsymbol{\beta}}$ the residual of unit $i$, with
\begin{equation}
\hat{\boldsymbol{\beta}}=\left[\sum_{i=1}^n(1-\pi_i)\frac{\mathbf{x}_i}{\pi_i}\frac{\mathbf{x}^{\text{T}}_i}{\pi_i}\right]^{-1}\sum_{i=1}^n(1-\pi_i)\frac{\mathbf{x}_i}{\pi_i}\frac{y_i}{\pi_i}
(\#eq:Beta)
\end{equation}
Working this out for simple random sampling without replacement ($\pi_i = n/N$ for $i = 1 \cdots N$) gives
\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{bal}}\right)=\left( 1-\frac{n}{N} \right) \frac{1}{n}\sum_{i=1}^n e_i^2\;,
(\#eq:VarMeanBalancedSI)
\end{equation}
With his design the residuals $e_i$ can be computed by fitting a linear regression model by ordinary least squares. For small sampling fractions $n/N$ and for balanced sampling from infinite poplations the finite population correction can be dropped from this variance estimator.

Balanced sampling is now illustrated with the field of simulated ECe values on the cotton farm in Uzbekistan. EM is used as balancing variable.

```{r, echo=F}
#randomize rows
set.seed(314)
N <- nrow(grdUzbekistan)
ord <- sample.int(N,size=N)
grdUzbekistan <- grdUzbekistan[ord,] 
```

```{r}
library(sampling)
#compute population size
N<-nrow(grdUzbekistan)
#set sample size
n<-40
#define matrix with covariate for balancing; first column of matrix must be filled with ones
X<-cbind(rep(1,times=N),grdUzbekistan$EM)
#compute inclusion probabilities; use equal probabilities
pik<-rep(n/N,times=N)
sampleind=samplecube(X=X,pik=pik,comment=FALSE,method=1)
mysample<-grdUzbekistan[sampleind==1,]
#estimate population mean
estimatedMean <- mean(mysample$ECe)
#estimate variance of estimated mean
lmsample<-lm(ECe~EM,data=mysample)
e<-residuals(lmsample)
S2e<-sum(e^2)/(n-2)
estimatedVarofMean<-S2e/n
```
Figure \@ref(fig:BalancedSampleCottonFarm) shows the result. The sample mean of EM equals `r round(mean(mysample$EM),1)`. The population mean of EM equals `r round(mean(grdUzbekistan$EM),1)`. 


```{r BalancedSampleCottonFarm, echo=F, out.width='100%', fig.asp=0.5, fig.cap="Balanced sample from the cotton farm (Uzbekistan), balanced on covariate EM"}
ggplot(data = grdUzbekistan) +
  geom_raster(mapping = aes(x = x1/1000, y = x2/1000, fill = EM)) +
  geom_tile(data=mysample,mapping = aes(x = x1/1000, y = x2/1000), colour="red",size=0.5, width=0.02, height=0.02, fill=NA)+
  scale_fill_gradientn(name="EM",colours=rev(terrain.colors(10))) +
  scale_x_continuous(name = "Easting (km)") +
  scale_y_continuous(name = "Northing (km)") +
  coord_equal()
```

Figure \@ref(fig:SamplingDistributionBalanced) shows the sampling distributions of the estimated mean of ECe for balanced sampling and simple random sampling, obtained by repeating the random sampling with both designs and estimation 1000 times.

```{r SamplingDistributionBalanced, out.width='70%', fig.asp=.8, fig.cap="Sampling distribution of estimated mean of ECe for balanced sampling and SI",echo=F, warning=F, cache=T}
estimatedMeansBal<-estimatedVarofMean<-samplemeanx<-estimatedMeansSI<-numeric(length=1000)

set.seed(314)
for (i in 1:1000) {
  sampleind=samplecube(X=X,pik=pik,comment=FALSE,method=1)
  mysample<-grdUzbekistan[sampleind==1,]

  estimatedMeansBal[i] <- mean(mysample$ECe)

  lmsample<-lm(ECe~EM,data=mysample)
  e<-residuals(lmsample)
  S2e<-sum(e^2)/(n-2)
  estimatedVarofMean[i]<-S2e/n
  
  samplemeanx[i] <- mean(mysample$EM)
  
  ids<-sample.int(nrow(grdUzbekistan), size = n, replace = FALSE)
  estimatedMeansSI[i]<-mean(grdUzbekistan$ECe[ids])
}
estimates<-data.frame(estimatedMeansBal,estimatedMeansSI,estimatedVarofMean,samplemeanx)
names(estimates)[c(1,2)]<-c("Bal","SI")
estimateslf<-melt(estimates[,c(1,2)])
ggplot(data = estimateslf) +
geom_boxplot(aes(y=value,x=variable)) +
geom_hline(yintercept=mean(grdUzbekistan$ECe),colour="red")+
  scale_x_discrete(name = "Sampling design") +
  scale_y_continuous(name = "Estimated mean ECe")

populationmeanx <- mean(grdUzbekistan$EM)
```

The empirical variance of the estimated population mean of the study variable ECe equals `r round(var(estimatedMeansBal),3)`. The gain in precision compated to simple random sampling equals `r round(var(estimatedMeansSI)/var(estimatedMeansBal),1)`. The mean of the 1000 estimated variances equals `r round(mean(estimatedVarofMean),3)`, showing that the approximate variance estimator performs well in this case. The sample mean of EM varies between the samples (Figure \@ref(fig:histSampleMeanEM)). The population mean of the balancing variable EM equals `r round(populationmeanx,1)`. In other words, many samples are not perfectly balanced on EM. This is not exceptional, in most cases perfect balance is impossible.

```{r histSampleMeanEM, out.width='60%', fig.asp=1, echo=F, fig.cap="Sampling distribution of sample mean of balancing variable EM"}
ggplot(data = estimates) +
  geom_histogram(aes(x=samplemeanx),binwidth=0.5,color="orange") +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Sample mean EM",limits=c(47,53))
```


### Balanced sampling with geographical spreading
When a sample is balanced on a covariate, this does not necessarily imply a good spread along the axis spanned by the covariate. Balancing and spreading of sampling locations are different things. For that reason I do not like the term spatially balanced sampling for sampling with spreading in geographical space. I prefer the term spatial coverage sampling for this.  

@Grafstrom2013 presented a method for selecting balanced samples that are also well-spread along the axes of one or more covariates. If we take for the spreading covariates Easting and Northing, this leads to balanced samples with good spatial coverage (balanced spatial coverage samples). when the residuals of the regression mdeol show spatial structure (are spatially correlated), the estimated population mean of the study variable becomes more precise thanks to the improved geographical spreading. Balanced samples with spreading can be selected with function `lcube` of R package `BalancedSampling`.

```{r lcube}
library(BalancedSampling)
sampleid=lcube(Xbal=X,Xspread=X,prob=pik)
mysample<-grdUzbekistan[sampleid,]
```

```{r, echo=F, out.width='100%', fig.asp=0.5, fig.cap="Balanced spatial coverage sample from the cotton farm (Uzbekistan), balanced on EM"}
ggplot(data = grdUzbekistan) +
  geom_raster(mapping = aes(x = x1/1000, y = x2/1000, fill = EM)) +
  geom_tile(data=mysample,mapping = aes(x = x1/1000, y = x2/1000), colour="red",size=0.5, width=0.02, height=0.02, fill=NA)+
  scale_fill_gradientn(name="EM",colours=rev(terrain.colors(10))) +
  scale_x_continuous(name = "Easting (km)") +
  scale_y_continuous(name = "Northing (km)") +
  coord_equal()
```
