<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Spatial sampling with R</title>
  <meta name="description" content="Spatial sampling with R">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="Spatial sampling with R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Spatial sampling with R" />
  
  
  

<meta name="author" content="Dick J. Brus">


<meta name="date" content="2018-06-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="IntroProbabilitySampling.html">
<link rel="next" href="STSI.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="1" data-path="GeneralIntro.html"><a href="GeneralIntro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="GeneralIntro.html"><a href="GeneralIntro.html#design-based-versus-model-based-approach"><i class="fa fa-check"></i><b>1.1</b> Design-based versus model-based approach</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="IntroProbabilitySampling.html"><a href="IntroProbabilitySampling.html"><i class="fa fa-check"></i><b>2</b> Probability sampling for estimating (sub)population parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="IntroProbabilitySampling.html"><a href="IntroProbabilitySampling.html#Voorst"><i class="fa fa-check"></i><b>2.1</b> Simulated population</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="SI.html"><a href="SI.html"><i class="fa fa-check"></i><b>3</b> Simple random sampling</a><ul>
<li class="chapter" data-level="3.1" data-path="SI.html"><a href="SI.html#horvitz-thompson-estimator"><i class="fa fa-check"></i><b>3.1</b> Horvitz-Thompson estimator</a></li>
<li class="chapter" data-level="3.2" data-path="SI.html"><a href="SI.html#VarMeanSI"><i class="fa fa-check"></i><b>3.2</b> Sampling variance of estimated mean, total and proportion</a></li>
<li class="chapter" data-level="3.3" data-path="SI.html"><a href="SI.html#confidence-interval-estimates"><i class="fa fa-check"></i><b>3.3</b> Confidence interval estimates</a></li>
<li class="chapter" data-level="3.4" data-path="SI.html"><a href="SI.html#arbitrary-haphazard-sampling-versus-probability-sampling"><i class="fa fa-check"></i><b>3.4</b> Arbitrary (haphazard) sampling versus probability sampling</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="STSI.html"><a href="STSI.html"><i class="fa fa-check"></i><b>4</b> Stratified random sampling</a><ul>
<li class="chapter" data-level="4.1" data-path="STSI.html"><a href="STSI.html#estimation-of-the-mean-and-its-sampling-variance"><i class="fa fa-check"></i><b>4.1</b> Estimation of the mean and its sampling variance</a></li>
<li class="chapter" data-level="4.2" data-path="STSI.html"><a href="STSI.html#confidence-interval-estimate"><i class="fa fa-check"></i><b>4.2</b> Confidence interval estimate</a></li>
<li class="chapter" data-level="4.3" data-path="STSI.html"><a href="STSI.html#cumrootf"><i class="fa fa-check"></i><b>4.3</b> Optimal stratification</a></li>
<li class="chapter" data-level="4.4" data-path="STSI.html"><a href="STSI.html#geographical-stratification"><i class="fa fa-check"></i><b>4.4</b> Geographical stratification</a></li>
<li class="chapter" data-level="4.5" data-path="STSI.html"><a href="STSI.html#STSIallocation"><i class="fa fa-check"></i><b>4.5</b> Allocation of sample size to strata</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="SY.html"><a href="SY.html"><i class="fa fa-check"></i><b>5</b> Systematic random sampling</a><ul>
<li class="chapter" data-level="5.1" data-path="SY.html"><a href="SY.html#EstVarSY"><i class="fa fa-check"></i><b>5.1</b> Estimation of mean and its sampling variance</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="pps.html"><a href="pps.html"><i class="fa fa-check"></i><b>6</b> Sampling with probabilities proportional to size</a><ul>
<li class="chapter" data-level="6.1" data-path="pps.html"><a href="pps.html#probability-proportional-to-size-sampling-with-replacement-ppswr"><i class="fa fa-check"></i><b>6.1</b> Probability-proportional-to-size sampling with replacement (ppswr)</a></li>
<li class="chapter" data-level="6.2" data-path="pps.html"><a href="pps.html#probability-proportional-to-size-sampling-without-replacement-ppswor"><i class="fa fa-check"></i><b>6.2</b> Probability-proportional-to-size sampling without replacement (ppswor)</a></li>
<li class="chapter" data-level="6.3" data-path="pps.html"><a href="pps.html#spatial-version-of-ppswor"><i class="fa fa-check"></i><b>6.3</b> Spatial version of ppswor</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Cl.html"><a href="Cl.html"><i class="fa fa-check"></i><b>7</b> Cluster random sampling</a><ul>
<li class="chapter" data-level="7.1" data-path="Cl.html"><a href="Cl.html#estimation-of-mean-and-its-sampling-variance"><i class="fa fa-check"></i><b>7.1</b> Estimation of mean and its sampling variance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Twostage.html"><a href="Twostage.html"><i class="fa fa-check"></i><b>8</b> Two-stage random sampling</a><ul>
<li class="chapter" data-level="8.1" data-path="Twostage.html"><a href="Twostage.html#estimation-of-mean-and-its-sampling-variance-1"><i class="fa fa-check"></i><b>8.1</b> Estimation of mean and its sampling variance</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html"><i class="fa fa-check"></i><b>9</b> Regression and ratio estimator</a><ul>
<li class="chapter" data-level="9.1" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html#regression-estimator"><i class="fa fa-check"></i><b>9.1</b> Regression estimator</a><ul>
<li class="chapter" data-level="9.1.1" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html#regression-estimator-for-stratified-simple-random-sampling"><i class="fa fa-check"></i><b>9.1.1</b> Regression estimator for stratified simple random sampling</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html#ratio-estimator"><i class="fa fa-check"></i><b>9.2</b> Ratio estimator</a><ul>
<li class="chapter" data-level="9.2.1" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html#ratio-estimator-for-stratified-simple-random-sampling"><i class="fa fa-check"></i><b>9.2.1</b> Ratio estimator for stratified simple random sampling</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="RegressionEstimator.html"><a href="RegressionEstimator.html#regression-estimator-with-unknown-mean-of-covariate"><i class="fa fa-check"></i><b>9.3</b> Regression estimator with unknown mean of covariate</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Balanced.html"><a href="Balanced.html"><i class="fa fa-check"></i><b>10</b> Balanced sampling</a><ul>
<li class="chapter" data-level="10.1" data-path="Balanced.html"><a href="Balanced.html#balanced-sample-versus-balanced-sampling-design"><i class="fa fa-check"></i><b>10.1</b> Balanced sample versus balanced sampling design</a></li>
<li class="chapter" data-level="10.2" data-path="Balanced.html"><a href="Balanced.html#unequal-inclusion-probabilities"><i class="fa fa-check"></i><b>10.2</b> Unequal inclusion probabilities</a><ul>
<li class="chapter" data-level="10.2.1" data-path="Balanced.html"><a href="Balanced.html#balanced-sampling-with-geographical-spreading"><i class="fa fa-check"></i><b>10.2.1</b> Balanced sampling with geographical spreading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Spatial sampling with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="SI" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Simple random sampling</h1>
<p>Simple random sampling is the most basic form of probability sampling. There are two subtypes:<br />
1. Simple random sampling with replacement (SIR).<br />
2. Simple random sampling without replacement (SI).</p>
<p>This distinction is irrelevant for infinite populations. In simple random sampling with replacement a population unit may be selected more than once.</p>
<p>In <code>R</code> a simple random sample with or without replacement can be selected by the function <code>sample.int</code> from the <code>base</code> package. For instance, a simple random sample without replacement of 10 units from a population of 100 units labeled as 1,2, … ,100, can be selected by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">314</span>)
<span class="kw">sample.int</span>(<span class="dv">100</span>,<span class="dt">size=</span><span class="dv">10</span>,<span class="dt">replace=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>##  [1] 10 27 76 22 20 29 23 35 51 68</code></pre>
<p>The number of units in the sample is referred to as the sample size (<span class="math inline">\(n=10\)</span> in the chunk above). Use argument <code>replace = TRUE</code> to select a simple random sample with replacement (SIR).</p>
<p>When the spatial population is <em>infinite</em> we do not have a list of all units in the population that can serve as a sampling frame. In this case we use a map showing the boundaries of the population as a sampling frame. The selection procedure is as follows:</p>
<ol style="list-style-type: decimal">
<li>Determine the minimum and maximum <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> coordinates of the field (bounding box).<br />
</li>
<li>Draw two independent (pseudo-)random coordinates <span class="math inline">\(s_{1,\mathrm{ran}}\)</span> and <span class="math inline">\(s_{2,\mathrm{ran}}\)</span>.<br />
</li>
<li>Use a point-in-polygon routine to determine wether <span class="math inline">\((s_{1,\mathrm{ran}}, s_{2,\mathrm{ran}})\)</span> falls within the area.<br />
</li>
<li>Repeat steps 2 and 3 until <span class="math inline">\(n\)</span> locations are selected.</li>
</ol>
<p>This procedure is implemented in the function <code>spsample</code> of <code>R</code> package <code>sp</code>. Alternatively, we may discretize the study area by a very fine grid, make a list of all the grid nodes, and sample from this list as before (see next chunk). So in this case the infinite population is represented as a very large finite population.</p>
<p>In the next chunk a simple random sample without replacement (SI) of size 40 is selected from Voorst. Note that the class of the <code>R</code> object <code>grdVoorst</code> is a <code>data.frame</code>, so the infinite population is represented by a very large finite population. The result is shown in Figure <a href="SI.html#fig:SampleSI">3.1</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">40</span>
N&lt;-<span class="kw">nrow</span>(grdVoorst)
<span class="kw">set.seed</span>(<span class="dv">314</span>)
units &lt;-<span class="st"> </span><span class="kw">sample.int</span>(N, <span class="dt">size =</span> n, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
mysample &lt;-<span class="st"> </span>grdVoorst[units,]
estimatedMean &lt;-<span class="st"> </span><span class="kw">mean</span>(mysample<span class="op">$</span>z)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:SampleSI"></span>
<img src="SpatialSampling_files/figure-html/SampleSI-1.png" alt="Simple random sample without replacement of size 40 from Voorst" width="100%" />
<p class="caption">
Figure 3.1: Simple random sample without replacement of size 40 from Voorst
</p>
</div>
<p>The population mean as estimated by the sample mean, i.e. the average of the measurements on the selected sampling units, equals 8.33.</p>
<div id="drop-outs" class="section level4 unnumbered">
<h4>Drop outs</h4>
<p>What to do with selected units that do not belong to target population, or cannot be observed for whatever reason (e.g. no permission)? In practice it may happen that inspection in the field shows that a selected sampling unit does not belong to the target population. For instance, in a soil survey the sampling location may happen to fall on a road or in a build-up area. Shifting this location to a nearby unit may lead to biased estimates of the population mean, i.e., a systematic error in the estimated mean. This can be avoided by discarding these units and to replace them by sampling units on a reserve list, selected in the same way, i.e., by the same type of sampling design. The order of sampling units in this list must be the order in which they are selected. Do not replace a deleted sampling unit by the nearest sampling unit from the reserve list, but by the first unit, not yet selected, from the reserve list.</p>
</div>
<div id="horvitz-thompson-estimator" class="section level2">
<h2><span class="header-section-number">3.1</span> Horvitz-Thompson estimator</h2>
<p>For any probability sampling design the population total can be estimated as a weightd sum of the observations</p>
<span class="math display" id="eq:HTTotal">\[\begin{equation}
\hat{t}(z)=\sum_{i=1}^n w_i z_i = \sum_{i=1}^n \frac{1}{\pi_i}z_i \;,
\tag{3.1}
\end{equation}\]</span>
<p>with <span class="math inline">\(n\)</span> the sample size (number of selected units), <span class="math inline">\(w_i\)</span> the weight attached to unit <span class="math inline">\(i\)</span>, <span class="math inline">\(z_i\)</span> the observed study variable for unit <span class="math inline">\(i\)</span>, and <span class="math inline">\(\pi_i\)</span> the probability that unit <span class="math inline">\(i\)</span> is included in the sample (in short, inclusion probability). This estimator is referred to as the Horvitz-Thompson estimator or <span class="math inline">\(\pi\)</span>-estimator. The <span class="math inline">\(\pi\)</span>-estimator for the <em>mean</em> is simply the <span class="math inline">\(\pi\)</span>-estimator for the total, divided by the total number of units in the population, <span class="math inline">\(N\)</span>:</p>
<span class="math display" id="eq:HTMean">\[\begin{equation}
\hat{\bar{z}}=\frac{1}{N} \sum_{i=1}^n w_i z_i \;.
\tag{3.2}
\end{equation}\]</span>
<p>So the observations are multiplied by a weight <span class="math inline">\(w_i\)</span> which equals the inverse of the inclusion probabilities. One may think of the weights as the number of units in the population a selected unit represents. So, in sampling with <em>unequal</em> probabilities, the larger this inclusion probability is, the smaller the weight attached to the observation on this unit, whereas if a unit is selected with a small selection probability, then the observation on this unit gets a large weight</p>
<p>For simple random sampling with replacement from a finite population the probability that a unit is selected in one draw equals <span class="math inline">\(1/N\)</span>. With <span class="math inline">\(n\)</span> draws the probability that a unit is included in the sample (inclusion probability) equals <span class="math inline">\(n/N\)</span>. It can be shown that for simple random sampling without replacement the inclusion probabilities are equal to those with simple random sampling with replacement <span class="citation">(Lohr 1999)</span>. Substituting this in the <span class="math inline">\(\pi\)</span>-estimator for the total gives for simple random sampling (with or without replacement)</p>
<span class="math display" id="eq:HTTotalSI">\[\begin{equation}
\hat{t}_{\text{SI}}(z)=\frac{N}{n}\sum_{i=1}^n z_i=N \bar{z}_s \;,
\tag{3.3}
\end{equation}\]</span>
<p>with <span class="math inline">\(\bar{z}_s\)</span> the (unweighted) <em>sample mean</em>. So for simple random sampling the <span class="math inline">\(\pi\)</span> estimator of the mean is the <em>unweighted</em> sample mean:</p>
<span class="math display" id="eq:HTMeanSI">\[\begin{equation}
\hat{\bar{z}}_{\text{SI}} = \bar{z}_s = \frac{1}{n}\sum_{i=1}^n z_i \;.
\tag{3.4}
\end{equation}\]</span>
<p>For <em>infinite</em> populations the total can be estimated by the (unweighted) sample mean multiplied by the area of the region of interest <span class="math inline">\(A\)</span>:</p>
<span class="math display" id="eq:HTTotalSIInfinite">\[\begin{equation}
\hat{t}_{\text{SI}}(z)= \frac{A}{n}\sum_{i=1}^{n}z_{i} \;.
\tag{3.5}
\end{equation}\]</span>
<p>Comparing this estimator with the estimator for the finite population total (Eq. <a href="SI.html#eq:HTTotal">(3.1)</a>) shows that the inclusion probability <span class="math inline">\(n/N\)</span> in the latter estimator has been replaced by <span class="math inline">\(n/A\)</span>, which can be interpreted as the inclusion probability , i.e., the number of sampling units per unit of area, or shortly, the .</p>
<p>The simulated population is now sampled 10000 times. For each sample the mean is estimated, as well as the variance of the estimated mean. How the variance is estimated, is explained hereafter in Section <a href="SI.html#VarMeanSI">3.2</a>. Figure <a href="SI.html#fig:SamplingDistributionSI">3.2</a> shows a histogram of the 10000 estimated means.</p>
<div class="figure" style="text-align: center"><span id="fig:SamplingDistributionSI"></span>
<img src="SpatialSampling_files/figure-html/SamplingDistributionSI-1.png" alt="Sampling distribution of estimated mean with SI of size 40" width="60%" />
<p class="caption">
Figure 3.2: Sampling distribution of estimated mean with SI of size 40
</p>
</div>
<p>If we would repeat the sampling an infinite number of times and make the width of the bins in the histogram infinitely small, then we obtain, after scaling so that the sum of the area under the curve equals 1, the <em>sampling distribution</em> of the estimated mean. Important summary statistics of this sampling distribution are:<br />
1. Expectation (mean)<br />
2. Variance, referred to as the <em>sampling</em> variance</p>
<p>When the expectation equals the population mean, then the estimator is <em>p-unbiased</em> (<em>design-unbiased</em>). Do not confuse the <em>population</em> variance and the <em>sampling</em> variance. The population variance (spatial variance) is a <em>population characteristic</em>, whereas the sampling variance is a <em>characteristic of a sampling strategy</em>, i.e. a combination of a sampling design and an estimator. The sampling variance quantifies our <em>uncertainty</em> about the mean. The sampling variance can be manipulated by changing the sample size <span class="math inline">\(n\)</span>, the type of sampling design, and the estimator. This has no effect on the population variance. The average of the 10^{4} estimated means equals 8.12, so the difference with the true population means equals -0.002. The variance of the 10^{4} estimated means equals 0.6.</p>
<div id="questions-1" class="section level4 unnumbered">
<h4>Questions:</h4>
<ol style="list-style-type: decimal">
<li>Compare the histogram of the estimated means with the histogram of the 7528 simulated values in the population (Figure <a href="IntroProbabilitySampling.html#fig:histogramVoorst">2.2</a>). Explain the differences.<br />
</li>
<li>What happens with the spread in the histogram (variance of estimated means) when the sample size <span class="math inline">\(n\)</span> is increased?<br />
</li>
<li>Suppose we would repeat the sampling a billion number of times, what would happen with the difference between the average of the estimated means and the population mean?</li>
</ol>
<p>In some cases one is interested in the proportion of the population (study area) satisfying a given condition. Think for instance of the proportion of trees in a forest infected by some disease, the proportion of an area in which a soil pollutant exceeds some critical threshold, or the proportion of an area where habitat conditions are suitable for some endangered species. A proportion is defined as the spatial mean of an 0/1 indicator <span class="math inline">\(y\)</span> with value 1 if the condition is satisfied, and 0 else. So for simple random sampling this proportion can be estimated by the same formula as for the mean (Eq. <a href="SI.html#eq:HTMeanSI">(3.4)</a>):</p>
<span class="math display" id="eq:HTProportionSI">\[\begin{equation}
\hat{p}_{\text{SI}} =  \frac{1}{n}\sum_{i=1}^n y_i \;.
\tag{3.6}
\end{equation}\]</span>
</div>
</div>
<div id="VarMeanSI" class="section level2">
<h2><span class="header-section-number">3.2</span> Sampling variance of estimated mean, total and proportion</h2>
<p>For simple random sampling of an infinite population and simple random sampling with replacement (SIR) of a finite population the sampling variance of the estimated mean equals</p>
<span class="math display" id="eq:VarMean">\[\begin{equation}
V\!\left(\hat{\bar{z}}_{\text{SIR}}\right)=\frac{S^{2}(z)}{n} \;,
\tag{3.7}
\end{equation}\]</span>
<p>with <span class="math inline">\(S^{2}(z)\)</span> the <em>population</em> variance, also referred to as the spatial variance. For finite populations this population variance is defined as</p>
<span class="math display" id="eq:PopulationVariance">\[\begin{equation}
S^{2}(z)=\frac{1}{N}\sum\limits_{i=1}^{N}\left(z_{i}-\bar{z}\right)^{2} \;,
\tag{3.8}
\end{equation}\]</span>
<p>and for infinite populations as</p>
<span class="math display" id="eq:PopulationVarianceInfinite">\[\begin{equation}
S^{2}(z) = \frac{1}{A} \int \limits_{\mathbf{s} \in \mathcal{A}} \left(z(\mathbf{s})-\bar{z}\right)^2\text{d}\mathbf{s} \;.
\tag{3.9}
\end{equation}\]</span>
<p>In practice we select only one sample, i.e. we do not repeat the sampling many times. Still it is possible to <em>estimate</em> the variance of the estimated means if we would repeat the sampling. In other words, we can estimate the sampling variance of the estimated mean from a single sample. We do so by estimating the population variance from the sample, and this estimate can be used on his turn to estimate the <em>sampling</em> variance of the estimated mean. For simple random sampling <em>with replacement</em> (SIR) from finite populations the sampling variance of the estimated mean can be estimated by</p>
<span class="math display" id="eq:EstVarMeanSIR">\[\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{SIR}}\right)=\frac{\widehat{S^2}(z)}{n}= \frac{1}{n\,(n-1)}\sum\limits_{i=1}^{n}\left(z_{i}-\hat{\bar{z}}\right)^{2} \;,
\tag{3.10}
\end{equation}\]</span>
<p>with <span class="math inline">\(\widehat{S^2}(z)\)</span> the <em>estimated</em> population variance. This estimator can also be used for <em>infinite</em> populations. For simple random sampling <em>without replacement</em> (SI) from finite populations the sampling variance of the estimated mean can be estimated by</p>
<span class="math display" id="eq:EstVarMeanSI">\[\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{SI}}\right)=\left(1-\frac{n}{N}\right)\frac{\widehat{S^2}(z)}{n} \;.
\tag{3.11}
\end{equation}\]</span>
<div id="questions-2" class="section level4 unnumbered">
<h4>Questions</h4>
<ol style="list-style-type: decimal">
<li>Is the sampling variance for simple random sampling without replacement larger or smaller than for simple random sampling with replacement, given the sample size <span class="math inline">\(n\)</span>? Explain your answer.<br />
</li>
<li>What is the effect of the population size <span class="math inline">\(N\)</span> on this difference?</li>
</ol>
<p>The term <span class="math inline">\(1-\frac{n}{N}\)</span> is referred to as the finite population correction (fpc).</p>
<p>In the sampling experiment described above, the average of the 10^{4} <em>estimated</em> sampling variances equals 0.597. The true sampling variance equals 0.599. So the difference is very small, indicating that the estimator of the sampling variance (Eq. <a href="SI.html#eq:EstVarMeanSI">(3.11)</a> is unbiased.</p>
</div>
<div id="questions-3" class="section level4 unnumbered">
<h4>Questions</h4>
<ol style="list-style-type: decimal">
<li>Above I computed the true sampling variance, i.e. the variance of the estimated means if we would repeat the sampling an infinite number of times. How can this true sampling variance be computed?<br />
</li>
<li>In reality we cannot compute this true sampling variance. Why not?</li>
</ol>
<p>The sampling variance of an estimated total of a finite population can be estimated by multiplying the estimated variance of the estimated mean by <span class="math inline">\(N^2\)</span>. For simple random sampling without replacement this estimator thus equals</p>
<span class="math display" id="eq:EstVarTotalSI">\[\begin{equation}
\widehat{V}\!\left(\hat{t}_{\text{SI}}(z)\right)=N^2 (1-\frac{n}{N})\frac{\widehat{S^{2}}(z)}{n} \;.
\tag{3.12}
\end{equation}\]</span>
<p>For simple random sampling with replacement (SIR) and simple random sampling of infinite populations the sampling variance of the estimated total can be estimated by</p>
<span class="math display" id="eq:EstVarTotalSIR">\[\begin{equation}
\widehat{V}\!\left(\hat{t}_{\text{SIR}}(z)\right)=A^2\frac{\widehat{S^{2}}(z)}{n} \;.
\tag{3.13}
\end{equation}\]</span>
<p>The sampling variance of an estimated proportion <span class="math inline">\(\hat{p}\)</span> can be estimated by</p>
<span class="math display" id="eq:EstVarProportionSI">\[\begin{equation}
\widehat{V}\!\left(\hat{p}_{\text{SI}}\right)=\left( 1-\frac{n}{N}\right) \frac{\hat{p}_{\text{SI}}(1-\hat{p}_{\text{SI}})}{n-1} \;.
\tag{3.14}
\end{equation}\]</span>
<p>The numerator in this estimator is an estimate of the population variance of the indicator. Note that this estimated population variance is divided by <span class="math inline">\(n-1\)</span>, and not by <span class="math inline">\(n\)</span> as in the estimator of the mean.</p>
</div>
</div>
<div id="confidence-interval-estimates" class="section level2">
<h2><span class="header-section-number">3.3</span> Confidence interval estimates</h2>
<p>A second way of expressing our uncertainty about the estimated total or mean (proportion) is to present not merely a single number, but an interval. The wider the interval, the more uncertain we are, and vice versa, the narrower the interval, the more confident we are about the estimate. To learn how to compute a confidence interval, I return to the sampling distribution of the estimated mean soil organic carbon concentration. Suppose we would like to compute the bounds of an interval <span class="math inline">\([a,b]\)</span> such that 5% of the estimated means is smaller than <span class="math inline">\(a\)</span>, and 5% is larger than <span class="math inline">\(b\)</span>. To compute the lower bound <span class="math inline">\(a\)</span> and upper bound <span class="math inline">\(b\)</span> of this 90%-interval, we must specify the distribution function. When the distribution of the target variable <span class="math inline">\(z\)</span> is approximately normal, then the sampling distribution of the estimated mean is also approximately normal, regardless of the sample size. The larger the sample size, the smaller the effect of the distribution of <span class="math inline">\(z\)</span> on the sampling distribution of the estimated mean. For instance, even when the distribution of <span class="math inline">\(z\)</span> is far from symmetric, then still the sampling distribution of the estimated mean is approximately normal if the sample size is large, say <span class="math inline">\(n &gt; 100\)</span>. This is the essence of the Central Limit Theorem. Above we already noticed that the sampling distribution is much less asymmetric than the histogram of the simulated values, and looks much more like a normal distribution. Assuming a normal distribution, the bounds of the 90%-interval are given by:</p>
<span class="math display" id="eq:CIBounds">\[\begin{equation}
\bar{z} \pm u_{1-(0.10/2)}\cdot \sqrt{V\!\left(\hat{\bar{z}}\right)} \;,
\tag{3.15}
\end{equation}\]</span>
<p>where <span class="math inline">\(u_{1-(0.10/2)}\)</span> is the <span class="math inline">\(0.95\)</span> quantile of the standard normal distribution. Note that in this equation the population mean <span class="math inline">\(\bar{z}\)</span> and the sampling variance of the estimated mean <span class="math inline">\(V\!\left(\hat{\bar{z}}\right)\)</span> are used. These quantities are unknown in practice, and must be estimated from the sample. Usually the standard normal distribution is replaced by the Student <span class="math inline">\(t\)</span> distribution, which is a bit wider than the standard normal distribution. In this way we account for the unknown population variance. This leads to the following bounds of the <span class="math inline">\(100(\alpha/2)\%\)</span> confidence interval estimate of the mean:</p>
<span class="math display" id="eq:CIBoundsStudent">\[\begin{equation}
\hat{\bar{z}}_{\text{SI}} \pm t^{(n-1)}_{1-\alpha /2}\cdot
\sqrt{\widehat{V}\!\left(\hat{\bar{z}}_{\text{SI}}\right)} \;,
\tag{3.16}
\end{equation}\]</span>
<p>where <span class="math inline">\(t^{(n-1)}_{1-\alpha /2}\)</span> is the <span class="math inline">\((1-\alpha /2)\)</span> quantile of the Student <span class="math inline">\(t\)</span> distribution with <span class="math inline">\((n-1)\)</span> degrees of freedom. The quantity <span class="math inline">\((1-\alpha)\)</span> is referred to as the confidence level. The larger the number of degrees of freedom <span class="math inline">\((n-1)\)</span>, the closer the Student <span class="math inline">\(t\)</span> distribution is to the standard normal distribution.</p>
<p>The interpretation and definition of a confidence interval is not straightforward. A common misinterpretation is that if the 90% confidence interval estimate of the mean equals <span class="math inline">\([a,b]\)</span>, then the probability that the population mean is in this interval equals 90%. This cannot be a correct interpretation, because the population mean is not a random variable, and consequently the probability that the population mean is in an interval does not exist. However, the estimated bounds of the confidence interval are random variables, because the estimated mean and also the estimated sampling variance varies between samples drawn with the sampling design, so it does make sense to attach a probability to this interval. Figure <a href="SI.html#fig:coverageconfinterval">3.3</a> shows the 90% confidence interval estimates of the mean for the first 100 simple random samples drawn above. Note that both the location and the width of the intervals differ between samples. For each sample I determined whether this interval covers the population mean.</p>
<div class="figure" style="text-align: center"><span id="fig:coverageconfinterval"></span>
<img src="SpatialSampling_files/figure-html/coverageconfinterval-1.png" alt="Estimated confidence intervals of the population mean" width="70%" />
<p class="caption">
Figure 3.3: Estimated confidence intervals of the population mean
</p>
</div>
<p>Out of the 10^{4} samples, 1174 samples do not cover the population mean.</p>
</div>
<div id="arbitrary-haphazard-sampling-versus-probability-sampling" class="section level2">
<h2><span class="header-section-number">3.4</span> Arbitrary (haphazard) sampling versus probability sampling</h2>
<p>In publications it is commonly stated that the sampling units were selected (more or less) at random (within strata), without further specification of how the sampling units were precisely selected. In statistical inference, the sampling units are subsequently treated as if they were selected by (stratified) simple random sampling. I would like to stress here that the term <em>random sampling</em> is often used in the meaning of <em>arbitrary</em> or <em>haphazard sampling</em> which is not equivalent to <em>probability sampling</em>. With probability sampling all units in the population have a positive probability of being selected, and the inclusion probabilities are known for all units. It is highly questionable whether this also holds for arbitrary and haphazard sampling. In arbitrary and haphazard sampling the sampling units are not selected by a probability mechanism. So the selection probabilities of the sampling units and of combinations of sampling units are unknown. This makes design-based estimation (design-based statistical inference) impossible, as this is based on the inclusion probabilities as determined by the sampling design, see the section on the Horvitz-Thompson estimator. The only way of statistical analysis of samples selected arbitrarily or haphazardly is model-based, i.e. a model of the spatial variation must be assumed.</p>
<div id="exercise-si.r" class="section level4 unnumbered">
<h4>Exercise (SI.R)</h4>
<ol style="list-style-type: decimal">
<li>Write an R script to select a simple random sample of size 100 from Voorst (data are in <code>Voorst.RData</code>).</li>
<li>Use the selected sample to estimate the population mean of SOM and its standard error (SOM is in the column z of the dataframe).</li>
<li>Compute the lower- and upperbound of the 95-percent confidence interval using the Student <span class="math inline">\(t\)</span> distribution, and check whether the population mean SOM is covered by the interval.</li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="IntroProbabilitySampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="STSI.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/DickBrus/SpatialSamplingwithR-master/03-SI.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
