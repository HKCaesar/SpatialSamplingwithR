# Probability sampling for estimating (sub)population parameters {#IntroProbabilitySampling}

To estimate population parameters like the mean or the total, *probability sampling* is most appropriate. Probability sampling is random sampling using a random number generator such that  
1. All population units have a probability larger than zero of being selected.  
2. The selection probability of each possible sample is known.

If the selection probability of each possible is known, for any unit in the population the probability that this unit is selected can be calculated as the sum of the selection probabilities over all samples that contains this unit. The selection probability of an individual unit is referred to as the inclusion probability of that unit.

A common misunderstanding is that with probability sampling the inclusion probabilities must be equal. With many sampling designs they are unequal. This is no problem as long as these probabilities are known.

There are many ways of selecting population units by probability sampling. The following sampling designs are described and illustrated in this book:  
* simple random sampling  
* stratified random sampling  
* systematic random sampling  
* sampling with probabilities proportional to size (pps-sampling)  
* cluster random sampling  
* two-stage random sampling  
* balanced sampling

## Horvitz-Thompson estimator
For any probability sampling design the population total can be estimated as a weighted sum of the observations

\begin{equation}
\hat{t}(z)_{\text{HT}}=\sum_{i=1}^n w_i z_i = \sum_{i=1}^n \frac{1}{\pi_i}z_i \;,
(\#eq:HTTotal)
\end{equation}

with $n$ the sample size (number of selected units), $w_i$ the weight attached to unit $i$, $z_i$ the observed study variable for unit $i$, and $\pi_i$ the probability that unit $i$ is included in the sample (in short, inclusion probability). This estimator is referred to as the Horvitz-Thompson estimator or $\pi$-estimator. 

So the observations are multiplied by a weight $w_i$ which equals the inverse of the inclusion probabilities. One may think of the weights as the number of units in the population represented by the selected units. So, in sampling with *unequal* probabilities, the larger this inclusion probability of a unit is, the fewer poplation units this unit represents, and the smaller the weight attached to the observation on this unit.

The $\pi$-estimator for the *mean* is simply the $\pi$-estimator for the total, divided by the total number of units in the population, $N$:

\begin{equation}
\hat{\bar{z}}=\frac{1}{N} \sum_{i=1}^n \frac{1}{\pi_i}z_i \;.
(\#eq:HTMean)
\end{equation}

## Simulated population {#Voorst}

The sampling designs are illustated with *simulated* populations (pseudo-populations). Figure \@ref(fig:Voorst) shows one of these simulated populations. The population consists of simulated soil organic matter (SOM) concentrations (in mass-percentages) in the topsoil in an area near Voorst (Netherlands). The field is simulated with data collected at 132 points in the past years by graduate students of Wageningen University. Besides the point data I used an existing soil map and a land use map in the simulation. I think the map is a realistic picture of SOM in the study area.

```{r Voorst,  out.width='100%', fig.asp=.333, echo=F, fig.cap="Simulated soil organic matter concentration in Voorst"}
ggplot(data = grdVoorst) +
        geom_raster(mapping = aes(x = s1/1000,y = s2/1000,fill = z)) +
        scale_x_continuous(name = "Easting  (km)") +
        scale_y_continuous(name = "Northing  (km)") +
        scale_fill_gradientn(name="SOM",colours=rev(terrain.colors(10))) +
        coord_equal(ratio = 1)
```

Figure \@ref(fig:histogramVoorst) shows that SOM is skewed to the right.

```{r histogramVoorst, out.width='70%', fig.asp=1, echo=F, fig.cap="Histogram of SOM in Voorst"}
ggplot(data = grdVoorst) +
  geom_histogram(aes(x=z),binwidth=2,color="orange") +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "z",limits=c(0,50))
```

Summary statistics are:
```{r, echo=F}
summary(grdVoorst$z)
```
The standard deviation of SOM in the population equals `r round(sqrt(var(grdVoorst$z)),1)`.

The simulated populations are taken as reality. This means that the true values are known everywhere, as if the study varable is observed without error everywhere in the area. So for Voorst we know SOM at any randomly selected location, as well as the population mean and total. So, for any sample selected from this simulated population, the SOM values for the selected sampling units are known, so that we can *estimate*  the population mean or total from this sample. The estimated mean (total) can be compared with the population mean (total). The difference between these two is the *sampling error* in the estimated mean (total).