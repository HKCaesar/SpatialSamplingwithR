# Cluster random sampling {#Cl}

With stratified random sampling with geographical strata and systematic random sampling the sampling units are well spread throughout the study area. In general this leads to an increase of the precision of the estimated mean (total). With large study areas the price to be paid for this is long travel times, so that less sampling units can be observed in a given survey period. In this situation it can be more efficient to select *spatial clusters* of sampling units. In cluster random sampling, once a cluster is selected, all sampling units in this cluster are observed. For this reason this design is also referred to as *single-stage* cluster random sampling. The clusters are not subsampled, as in two-stage random sampling (see Chapter \@ref(Twostage)). A popular cluster shape is a transect. The reason is that the individual sampling units of a transect can easily be located in the field, which was a big advantage in the pre-GPS era.

The implementation of cluster random sampling is not straightforward. I have seen many examples in the literature of an improper implementation of this sampling design. A proper selection technique is as follows [@gru06]. In the first step a `starting point (unit)' is selected, for instance by simple random sampling. Then the remaining units of the cluster to which the starting point belongs are identified by making use of the definition of the cluster. For instance, with clusters defined as E-W oriented transects, with a cluster spacing of 100 m, all points east and west of the starting point at a distance of 100 m, 200 m *et cetera* that fall inside the study area are selected. These two steps are repeated until the required number of clusters is selected.

A requirement of a valid selection method is that the same cluster is selected, regardless of which of its locations is used as a starting point. In the example above this is the case: regardless of which of the points on the transect is selected first, the final set of points selected is the same.

An example of an improper implementation of this sampling design is the following. A cluster is defined as an E-W oriented transect of four points with a mutual spacing of 100 m. A cluster is selected by randomly selecting a starting point. The remaining three points of the cluster are selected E of this starting point. Points outside the study area are ignored. With this selection method the set of selected points is *not* independent of the starting point, and therefore is invalid.

Note that the size of the clusters, i.e. the number of points (units) of a cluster need not be constant. With the proper selection method described above the selection probability of a cluster is proportional to its size (pps-sampling). With irregularly shaped study areas the size of the cluster can vary strongly. The size of the clusters can be controlled by subdividing the study area into blocks, for instance stripes perpendicular to the direction of the transects, or square blocks in case the clusters are grids. In this case, the remaining units are identified by extending the transect or grid until the boundary of the block. With irregularly shaped areas blocking will not eliminate entirely the variation in cluster sizes.

The R code below shows the selection of E-W oriented transects in Voorst. In order to delimit the length of the transects the study area is split into six 1 km $\times$ 1 km blocks. Note that these blocks do not serve as strata. When used as strata, from each block one or more clusters would be selected, see Section \@ref(StratifiedCl).  As a first step in the R script all clusters in the finite representation of the population are constructed. The cluster-id is added to the sampling frame. Each point belongs exactly to one cluster. Then several clusters are selected with probabilities proportional to size and with replacement (ppswr). This is done by simple random sampling with replacement of points, and identifying the clusters to which these points belong. Finally, all points of the selected clusters are included in the sample.

```{r SampleCl}
#compute local coordinates
s1local <- grdVoorst$s1-min(grdVoorst$s1)
s2local <- grdVoorst$s2-min(grdVoorst$s2)
#set spacing of points within clusters
spacing <- 100 
s1f <- as.factor(s1local%%spacing)
s2f <- as.factor(s2local)
#construct clusters (E-W oriented transects within zones)
grdVoorst$cluster <- as.character(interaction(s1f,s2f,as.factor(grdVoorst$zone)))
grdVoorst$id <- seq(1:nrow(grdVoorst))
#now define function for cluster random sampling
cl <- function(sframe,d) {
  units<-sample.int(nrow(sframe),size=d,replace=TRUE)
  ids.pnt<-sframe$id[units]
  ids.cl <- sframe$cluster[units]
  mysample <- sframe[sframe$cluster %in% ids.cl,]
  mysample$start <- 0
  mysample$start[mysample$id%in%ids.pnt] <- 1
  return(mysample)
}
#set number of cluster draws
d<-4 
set.seed(314)
mysample <- cl(sframe=grdVoorst,d=d)
cls <- unique(mysample$cluster)
cellsize<-25
for (i in 1:d) {
  mysample$s1[mysample$cluster==cls[i]] <- mysample$s1[mysample$cluster==cls[i]]+runif(1,min=-cellsize/2,max=cellsize/2)
  mysample$s2[mysample$cluster==cls[i]] <- mysample$s2[mysample$cluster==cls[i]]+runif(1,min=-cellsize/2,max=cellsize/2)
}
```

Figure \@ref(fig:ClVoorst) shows the selected sample. The total number of selected points equals `r nrow(mysample)`. Similar to systematic random sampling, with cluster random sampling  the total sample size is random, so that we do not have perfect control of the total sample size. This is because in this case the sizes (number of points) of the clusters is not constant but varies.

```{r ClVoorst,echo=F,out.width='100%', fig.asp=.333, fig.cap="Cluster random sample from Voorst"}
ggplot(grdVoorst) +        
  geom_raster(mapping = aes(x = s1/1000, y = s2/1000,fill=as.factor(zone))) +
  geom_point(data=mysample, mapping = aes(x = s1/1000, y = s2/1000), size = 1.5) +
  scale_x_continuous(name = "Easting (km)") +
  scale_y_continuous(name = "Northing (km)") +
  coord_fixed()+
  theme(legend.position = "none")
```

The output `mysample` of function `cl` in the chunk above has a column named `start'. This is an indicator with value 1 if this point of the cluster is selected first, and 0 else. When in the field it appears that the first selected point of a cluster does not belong to the target population, all other points of that cluster are also dropped. This is to keep the selection probabilities of the clusters exactly proportional to their size.

## Estimation of mean and its sampling variance
With pps-sampling with replacement of clusters the population mean is estimated unbiasedly by (see chunk hereafter):
\begin{equation}
\hat{\bar{z}}_{\mathrm{Cl}}=
\frac{1}{d}\sum\limits_{i=1}^{d}\hat{\bar{z}}_{i} \;,
(\#eq:EstMeanCl)
\end{equation}
where $d$ is the number of times a cluster is drawn (number of draws) and $\hat{\bar{z}}_{i}$ is the sample mean of cluster $i$.

The sampling variance can be estimated by
\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\mathrm{Cl}}\right)=\frac{\widehat{S^2}_{\mathrm{Cl}}}{d} \;,
(\#eq:VarEstMeanCl)
\end{equation}
where $\widehat{S^2}_{\mathrm{Cl}}$ is the estimated variance of *estimated* cluster means (between cluster variance)
\begin{equation}
\widehat{S^2}_{\mathrm{Cl}} = \frac{1}{d-1}\sum_{i=1}^{d}(\hat{\bar{z}}_{i}-\hat{\bar{z}}_{\mathrm{Cl}})^2 \;,
(\#eq:S2EstMeanCl)
\end{equation}

```{r}
clusterMeans<-tapply(mysample$z,INDEX=mysample$cluster,FUN=mean)
estimatedMean<-mean(clusterMeans)
estimatedVarMean<-var(clusterMeans)/d
```

Note that the size of the clusters (number of locations) does not appear in these formulas. This simplicity is due to the fact that the clusters are selected with probabilities proportional to size. The effect of the cluster size on the variance is implicitly accounted for. To understand this, consider that larger clusters result in smaller variance among their means.

Figure \@ref(fig:SamplingDistributionCl) shows the sampling distributions of the estimated mean with cluster random sampling and simple random sampling, obtained by repeating the random sampling with each design and estimation 10,000 times. For simple random samples the size is equal to the expected sample size of the cluster random sampling design.

```{r SamplingDistributionCl, out.width='70%', fig.asp=.8, fig.cap="Sampling distribution of estimated mean with Cl and SI", echo=F, cache=T}
NUMBER_OF_SAMPLES <- 10000
meanz <- Vmeanz <- meanzSI <- sampleSizes <- numeric(length=NUMBER_OF_SAMPLES)

#compute size of clusters
clustersize <- tapply(grdVoorst$z,INDEX=grdVoorst$cluster,FUN=length)

#compute expected sample size
p <- clustersize/sum(clustersize)
mean.n <- round(d*sum(p*clustersize),0)

SI <- function(sframe, n) {
    units <- sample.int(nrow(sframe), size = n, replace = TRUE)
    mysample <- sframe[units,]
    return(mysample)
}

for (i in 1:NUMBER_OF_SAMPLES) {
    mysample <- cl(sframe=grdVoorst,d=d)
    clusterMeans<-tapply(mysample$z,INDEX=mysample$cluster,FUN=mean)
    meanz[i]<-mean(clusterMeans)
    Vmeanz[i]<-var(clusterMeans)/d
    sampleSizes[i]<-nrow(mysample)
    mySIsample <- SI(grdVoorst,n=mean.n)
    meanzSI[i] <- mean(mySIsample$z)
}

estimates<-data.frame(meanz,meanzSI)
names(estimates)<-c("Cl","SI")
estimateslf<-melt(estimates)

ggplot(data = estimateslf) +
    geom_boxplot(aes(y=value,x=variable)) +
    geom_hline(yintercept=mean(grdVoorst$z),colour="red")+
    scale_x_discrete(name = "Sampling design") +
    scale_y_continuous(name = "Estimated mean SOM")

meanmean<-mean(meanz)
varmean<-var(meanz)
meanvarmean<-mean(Vmeanz)
varmeanSI <- var(meanzSI)
```

The variance of the `r NUMBER_OF_SAMPLES` means with cluster random sampling equals `r round(varmean,3)`.  This is considerably larger than with simple random sampling: `r round(varmeanSI,3)`. The large variance is cause by the strong spatial clustering of points. This may save travel time, although in this small study area this is possibly rather limited. For large study areas the saving of travel time in the field with cluster random sampling can be considerable. The average of the estimated variances with cluster random sampling equals `r round(meanvarmean,3)`. This indicates that the estimator of the variance, Equation \@ref(eq:VarEstMeanCl), is unbiased. Figure \@ref(fig:histsamplesizeCl) shows the sampling distribution of the sample size. The expected sample size equals `r round(mean.n,2)`. 

```{r histsamplesizeCl, fig.width=4,fig.height=4,fig.cap="Sampling distribution of sample size", echo=F}
ggplot() +
        geom_histogram(aes(x=sampleSizes),binwidth=1,colour="orange") +
        scale_y_continuous(name = "Frequency") +
        scale_x_continuous(name = "Sample size")
#summary(sampleSizes)
```

## Stratified cluster random sampling {#StratifiedCl}

The basic sampling designs stratified random sampling (Chapter \@ref(STSI)) and cluster random sampling can be combined into stratified cluster random sampling. So instead of selecting simple random samples from the strata, clusters are randomly selected. Figure \@ref(fig:STCl) shows a stratified cluster random sample from Voorst. The strata consist of three 2 km $times$ 1 km blocks, obtained by joining two neighbouring 1 km $times$ 1 km blocks (Figure \@ref(fig:ClVoorst)). The clusters are the same as before, i.e. E-W oriented transects within 1 km $times$ 1 km blocks, with a inter-point spacing of 100 m.  Within each stratum two times a cluster is selected by ppswr. The stratification avoids the clustering of the selected transects in one part of the study area. Compared to (unstratified) cluster random sampling, the geographical spreading of the clusters is improved, which may lead to an increase of the precision of the estimated population mean.

```{r STCl, out.width='100%', fig.asp=.333, fig.cap="Stratified cluster random sample from Voorst", echo=F}
#construct strata from zones
grdVoorst$zonef <- as.factor(grdVoorst$zone)
levels(grdVoorst$zonef) <- rep(c("A","B","C"),each=2)
#compute stratum sizes
Nh <- tapply(grdVoorst$z,INDEX=grdVoorst$zonef,FUN=length)
#set number of cluster draws per stratum
dh <- c(2,2,2)
set.seed(324)
stratumlabels <- unique(grdVoorst$zonef)
mysample<-NULL
for (i in 1:3) {
  grdh <- grdVoorst[grdVoorst$zonef==stratumlabels[i],]
  mysampleh <- cl(sframe=grdh,d=dh[i])
  mysample <- rbind(mysample,mysampleh)
}

cls <- unique(mysample$cluster)
for (i in 1:length(cls)) {
  mysample$s1[mysample$cluster==cls[i]] <- mysample$s1[mysample$cluster==cls[i]]+runif(1,min=-cellsize/2,max=cellsize/2)
  mysample$s2[mysample$cluster==cls[i]] <- mysample$s2[mysample$cluster==cls[i]]+runif(1,min=-cellsize/2,max=cellsize/2)
}

ggplot(grdVoorst) +        
  geom_raster(mapping = aes(x = s1/1000, y = s2/1000,fill=zonef)) +
  geom_point(data=mysample, mapping = aes(x = s1/1000, y = s2/1000), size = 1.5) +
  geom_vline(xintercept=c(202.5195,204.5195,206.5195))+
  scale_x_continuous(name = "Easting (km)") +
  scale_y_continuous(name = "Northing (km)") +
  coord_fixed()+
  theme(legend.position = "none")
#reload Voorst so that added columns are not in grdVoorst anymore
load(file="Voorst.RData")
```

The population mean is estimated by first estimating the stratum means using Equation \@ref(eq:EstMeanCl), followed by computing the weighted average of the estimated stratum means using Equation \@ref(eq:HTMeanSTSI2). The variance of the estimated population mean is estimated in the same way, by first estimating the variance of the estimated stratum means using Equation \@ref(eq:VarEstMeanCl), followed by computing the weighted average of the estimated variances of the estimated stratum means (Equation \@ref(eq:EstVarMeanSTSI)).

#### Exercise ([StratifiedCluster.R](https://github.com/DickBrus/SpatialSamplingwithR/blob/master/Exercises/StratifiedCluster.R)) {-}
1. Write an R script to select a stratified cluster random sample from Voorst, using the 2 km $\times$ 1 km blocks of Figure \@ref(fig:STCl) as strata. Select in each stratum two times a cluster with probabilities proportional to size   
2. Estimate the population mean and its standard error  

#### Questions {-}  
1. Why is it attractive to select at least two clusters per stratum?  
